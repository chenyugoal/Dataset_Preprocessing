{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recorded-anthony",
   "metadata": {},
   "source": [
    "# Omnidirectional Lifelong Learning Across Datasets\n",
    "\n",
    "\n",
    "Image Datasets:\n",
    "\n",
    "- fgvc-aircraft-2013b\n",
    "    - 10000 samples, 100 classes\n",
    "    - Preprocessing Done\n",
    "    - devided into 5 tasks, 20 classes per task?\n",
    "- Sun 397\n",
    "    - 397 classes, at least 100 images per class\n",
    "    \n",
    "\n",
    "Thoughts:\n",
    "\n",
    "- Maybe I should only use datasets for object detection.In that case, I should exclude Sun397."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "focused-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proglearn.deciders import SimpleArgmaxAverage\n",
    "from proglearn.progressive_learner import ProgressiveLearner\n",
    "from proglearn.transformers import NeuralClassificationTransformer, TreeClassificationTransformer\n",
    "from proglearn.voters import TreeClassificationVoter, KNNClassificationVoter\n",
    "\n",
    "from tensorflow.keras.backend import clear_session # To avoid OOM error when using dnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-sitting",
   "metadata": {},
   "source": [
    "## Aircraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tender-commissioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_aircraft_image = 'F:/Programming/Python/NDD/datasets_resized/fgvc-aircraft-2013b/data/images/'\n",
    "path_sun_image = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "heard-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "\n",
    "f = open(\"F:/Programming/Python/NDD/datasets_resized/fgvc-aircraft-2013b/data/train.txt\", \"r\")\n",
    "\n",
    "lines = f.readlines()\n",
    "for l in lines:\n",
    "    img = cv2.imread(\"F:/Programming/Python/NDD/datasets_resized/fgvc-aircraft-2013b/data/images/\"+l.split(' ')[0])\n",
    "    x_train.append(img)\n",
    "    y_train.append(int(l.split(' ')[1]))\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "south-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]\n",
    "\n",
    "f = open(\"F:/Programming/Python/NDD/datasets_resized/fgvc-aircraft-2013b/data/test.txt\", \"r\")\n",
    "\n",
    "lines = f.readlines()\n",
    "for l in lines:\n",
    "    img = cv2.imread(\"F:/Programming/Python/NDD/datasets_resized/fgvc-aircraft-2013b/data/images/\"+l.split(' ')[0])\n",
    "    x_test.append(img)\n",
    "    y_test.append(int(l.split(' ')[1]))\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "greatest-branch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (6667, 32, 32, 3)\n",
      "y_train shape:  (6667,)\n",
      "y_train:  [  1   1   1 ... 100 100 100]\n",
      "y_test:  [  1   1   1 ... 100 100 100]\n",
      "x_test shape:  (3333, 32, 32, 3)\n",
      "y_test shape:  (3333,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape: ',x_train.shape)\n",
    "print('y_train shape: ',y_train.shape)\n",
    "print('y_train: ',y_train)\n",
    "print('y_test: ',y_test)\n",
    "print('x_test shape: ',x_test.shape)\n",
    "print('y_test shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "overall-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening\n",
    "x_train_f = x_train.reshape((x_train.shape[0],-1))\n",
    "x_test_f = x_test.reshape((x_test.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "occasional-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import save\n",
    "\n",
    "np.save('data/x_train.npy',x_train)\n",
    "np.save('data/y_train.npy',y_train)\n",
    "\n",
    "np.save('data/x_test.npy',x_test)\n",
    "np.save('data/y_test.npy',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-librarian",
   "metadata": {},
   "source": [
    "### sklearn Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dramatic-freight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, random_state=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=30)\n",
    "clf.fit(x_train_f, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "unknown-ferry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy:  0.10081008100810081\n",
      "It is better than random choosing, 1/100.\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(x_test_f)\n",
    "acc = np.sum(prediction == y_test)/prediction.shape[0]\n",
    "print('The Accuracy: ',acc)\n",
    "print('It is better than random choosing, 1/100.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-latter",
   "metadata": {},
   "source": [
    "## Sun 397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-liberal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progressivelearning",
   "language": "python",
   "name": "progressivelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
